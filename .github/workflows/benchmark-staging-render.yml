name: Benchmark Staging Render

on:
  workflow_dispatch:
    inputs:
      duration_seconds:
        description: "Benchmark clip duration in seconds"
        required: true
        default: "8"

concurrency:
  group: staging-render-benchmark
  cancel-in-progress: false

jobs:
  benchmark:
    runs-on: ubuntu-latest
    environment:
      name: staging
      url: https://dev.poverlay.com
    permissions:
      contents: read
    steps:
      - name: Validate required secrets
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_USER }}
          VPS_SSH_KEY: ${{ secrets.VPS_SSH_KEY }}
        run: |
          set -euo pipefail
          [[ -n "${VPS_HOST}" ]] || { echo "::error::Missing secret VPS_HOST"; exit 1; }
          [[ -n "${VPS_USER}" ]] || { echo "::error::Missing secret VPS_USER"; exit 1; }
          [[ -n "${VPS_SSH_KEY}" ]] || { echo "::error::Missing secret VPS_SSH_KEY"; exit 1; }

      - name: Start SSH agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.VPS_SSH_KEY }}

      - name: Add server to known_hosts
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_PORT: ${{ secrets.VPS_PORT }}
        run: |
          set -euo pipefail
          PORT="${VPS_PORT:-22}"
          mkdir -p ~/.ssh
          ssh-keyscan -H -p "${PORT}" "${VPS_HOST}" >> ~/.ssh/known_hosts

      - name: Run render benchmark matrix on staging VPS
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_USER }}
          VPS_PORT: ${{ secrets.VPS_PORT }}
          DURATION_SECONDS: ${{ inputs.duration_seconds }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          PORT="${VPS_PORT:-22}"
          DURATION="${DURATION_SECONDS:-8}"
          BENCH_BASE="/tmp/poverlay-staging-bench-${RUN_ID}"

          ssh -p "${PORT}" "${VPS_USER}@${VPS_HOST}" "DURATION='${DURATION}' BENCH_BASE='${BENCH_BASE}' bash -se" <<'EOF'
          set -euo pipefail
          cd /opt/poverlay-staging

          python3 - <<'PY'
import csv
import json
import os
import re
import subprocess
import sys
import time
from pathlib import Path


ROOT = Path("/opt/poverlay-staging")
BENCH_BASE = Path(os.environ["BENCH_BASE"])
DURATION_SECONDS = int(float(os.environ.get("DURATION", "8")))
SAMPLES_VIDEO = ROOT / "samples" / "GX010288.MP4"
SAMPLES_GPX = ROOT / "samples" / "February 7, 2026 - Breckenridge Resort.gpx"
FONT = ROOT / "apps/api/app/static/fonts/Orbitron-Bold.ttf"
CONFIG_DIR = ROOT / "data/gopro-config"
RUNNER = ROOT / "scripts/gopro-dashboard-local.sh"

if not SAMPLES_VIDEO.exists():
    raise RuntimeError(f"Missing sample video: {SAMPLES_VIDEO}")
if not SAMPLES_GPX.exists():
    raise RuntimeError(f"Missing sample GPX: {SAMPLES_GPX}")
if not RUNNER.exists():
    raise RuntimeError(f"Missing renderer launcher: {RUNNER}")

BENCH_BASE.mkdir(parents=True, exist_ok=True)
clips_dir = BENCH_BASE / "clips"
layouts_dir = BENCH_BASE / "layouts"
outputs_dir = BENCH_BASE / "outputs"
logs_dir = BENCH_BASE / "logs"
for path in [clips_dir, layouts_dir, outputs_dir, logs_dir]:
    path.mkdir(parents=True, exist_ok=True)

resolutions = [
    ("720p", 1280, 720),
    ("1080p", 1920, 1080),
    ("2_7k", 2704, 1520),
    ("4k", 3840, 2160),
    ("5_3k", 5312, 2988),
]
profiles = ["h264-fast", "h264-source", "h264-4k-compat"]

creation_time = subprocess.check_output(
    [
        "ffprobe",
        "-v",
        "error",
        "-show_entries",
        "format_tags=creation_time",
        "-of",
        "default=nw=1:nk=1",
        str(SAMPLES_VIDEO),
    ],
    text=True,
).strip()
if creation_time.endswith("Z"):
    creation_ts = creation_time.replace("Z", "+00:00")
else:
    creation_ts = creation_time

print(f"[bench] source creation_time={creation_time}")
print(f"[bench] clip duration={DURATION_SECONDS}s")

# Generate deterministic test clips at each resolution.
for resolution_id, width, height in resolutions:
    clip_path = clips_dir / f"{resolution_id}.mp4"
    subprocess.run(
        [
            "ffmpeg",
            "-hide_banner",
            "-y",
            "-ss",
            "00:00:30",
            "-t",
            str(DURATION_SECONDS),
            "-i",
            str(SAMPLES_VIDEO),
            "-vf",
            f"scale={width}:{height}:flags=lanczos",
            "-an",
            "-c:v",
            "libx264",
            "-preset",
            "veryfast",
            "-crf",
            "20",
            str(clip_path),
        ],
        check=True,
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
    )

    # Set mtime so --video-time-start file-modified aligns to GPX.
    subprocess.run(
        [
            "python3",
            "-c",
            (
                "from datetime import datetime;"
                "import os,sys;"
                "dt=datetime.fromisoformat(sys.argv[2].replace('Z','+00:00'));"
                "os.utime(sys.argv[1], (dt.timestamp(), dt.timestamp()))"
            ),
            str(clip_path),
            creation_ts,
        ],
        check=True,
    )

# Build map-on/map-off layouts for each resolution.
sys.path.insert(0, str((ROOT / "apps/api").resolve()))
from app.layouts import render_layout_xml  # noqa: E402

for resolution_id, width, height in resolutions:
    for maps_enabled in [False, True]:
        layout_path = layouts_dir / f"{resolution_id}-maps-{'on' if maps_enabled else 'off'}.xml"
        layout_path.write_text(
            render_layout_xml(
                width=width,
                height=height,
                theme_name="powder-neon",
                include_maps=maps_enabled,
                layout_style="summit-grid",
                speed_units="mph",
            ),
            encoding="utf-8",
        )

timer_re = re.compile(r"Timer\(drawing frames - Called: (\d+), Total: ([0-9.]+), Avg: ([0-9.]+), Rate: ([0-9.]+)\)")


def ffprobe_value(path: Path, key: str) -> str:
    return subprocess.check_output(
        [
            "ffprobe",
            "-v",
            "error",
            "-select_streams",
            "v:0",
            "-show_entries",
            f"stream={key}",
            "-of",
            "default=nw=1:nk=1",
            str(path),
        ],
        text=True,
    ).strip()


def run_case(*, scenario: str, resolution_id: str, profile: str, maps_enabled: bool, fps_mode: str, fixed_fps: float | None):
    clip_path = clips_dir / f"{resolution_id}.mp4"
    output_path = outputs_dir / f"{scenario}.mp4"
    log_path = logs_dir / f"{scenario}.log"
    layout_path = layouts_dir / f"{resolution_id}-maps-{'on' if maps_enabled else 'off'}.xml"

    cmd = [
        str(RUNNER),
        "--font",
        str(FONT),
        "--gpx",
        str(SAMPLES_GPX),
        "--use-gpx-only",
        "--video-time-start",
        "file-modified",
        "--layout",
        "xml",
        "--layout-xml",
        str(layout_path),
        "--map-style",
        "osm",
        "--units-speed",
        "mph",
        "--units-altitude",
        "feet",
        "--units-distance",
        "mile",
        "--units-temperature",
        "degF",
        "--config-dir",
        str(CONFIG_DIR),
        "--cache-dir",
        str(CONFIG_DIR),
        "--profile",
        profile,
    ]

    if fps_mode == "source_rounded":
        cmd.append("--overlay-fps-round")
    elif fps_mode == "fixed":
        cmd.extend(["--overlay-fps", str(fixed_fps if fixed_fps is not None else 30.0)])

    cmd.extend(["--", str(clip_path), str(output_path)])

    started = time.perf_counter()
    completed = subprocess.run(
        cmd,
        text=True,
        capture_output=True,
        check=False,
        env={**os.environ, "PYTHONUNBUFFERED": "1"},
    )
    elapsed = time.perf_counter() - started

    combined = f"{completed.stdout}\n{completed.stderr}".strip()
    log_path.write_text(combined, encoding="utf-8")

    timer_match = timer_re.search(combined)
    draw_frames = int(timer_match.group(1)) if timer_match else None
    draw_total_s = float(timer_match.group(2)) if timer_match else None
    draw_rate_fps = float(timer_match.group(4)) if timer_match else None

    output_width = ""
    output_height = ""
    output_fps = ""
    output_duration = ""
    if completed.returncode == 0 and output_path.exists():
        output_width = ffprobe_value(output_path, "width")
        output_height = ffprobe_value(output_path, "height")
        output_fps = ffprobe_value(output_path, "avg_frame_rate")
        output_duration = ffprobe_value(output_path, "duration")

    wall_x_realtime = elapsed / DURATION_SECONDS if DURATION_SECONDS > 0 else None
    print(
        "[bench]",
        scenario,
        f"ret={completed.returncode}",
        f"elapsed={elapsed:.2f}s",
        f"x_rt={wall_x_realtime:.2f}x" if wall_x_realtime is not None else "x_rt=n/a",
    )

    return {
        "scenario": scenario,
        "resolution_id": resolution_id,
        "profile": profile,
        "maps_enabled": maps_enabled,
        "fps_mode": fps_mode,
        "fixed_fps": fixed_fps if fixed_fps is not None else "",
        "clip_duration_s": DURATION_SECONDS,
        "elapsed_s": round(elapsed, 3),
        "wall_x_realtime": round(wall_x_realtime, 3) if wall_x_realtime is not None else "",
        "draw_frames": draw_frames if draw_frames is not None else "",
        "draw_total_s": round(draw_total_s, 3) if draw_total_s is not None else "",
        "draw_rate_fps": round(draw_rate_fps, 3) if draw_rate_fps is not None else "",
        "return_code": completed.returncode,
        "output_width": output_width,
        "output_height": output_height,
        "output_fps": output_fps,
        "output_duration": output_duration,
        "log_path": str(log_path),
    }


cases: list[dict] = []

# Main matrix: all resolutions x all profiles, maps off, source fps.
for resolution_id, _w, _h in resolutions:
    for profile in profiles:
        cases.append(
            {
                "scenario": f"main-{resolution_id}-{profile}",
                "resolution_id": resolution_id,
                "profile": profile,
                "maps_enabled": False,
                "fps_mode": "source_exact",
                "fixed_fps": None,
            }
        )

# Map overhead matrix: all resolutions on h264-source, maps on.
for resolution_id, _w, _h in resolutions:
    cases.append(
        {
            "scenario": f"maps-on-{resolution_id}-h264-source",
            "resolution_id": resolution_id,
            "profile": "h264-source",
            "maps_enabled": True,
            "fps_mode": "source_exact",
            "fixed_fps": None,
        }
    )

# FPS sensitivity matrix on two representative resolutions.
for resolution_id in ["1080p", "5_3k"]:
    for fps_mode, fixed in [("source_rounded", None), ("fixed", 15.0), ("fixed", 30.0)]:
        cases.append(
            {
                "scenario": f"fps-{resolution_id}-h264-source-{fps_mode}-{fixed if fixed else 'na'}",
                "resolution_id": resolution_id,
                "profile": "h264-source",
                "maps_enabled": False,
                "fps_mode": fps_mode,
                "fixed_fps": fixed,
            }
        )

rows = [run_case(**case) for case in cases]

csv_path = BENCH_BASE / "results.csv"
json_path = BENCH_BASE / "results.json"
summary_path = BENCH_BASE / "summary.json"

with csv_path.open("w", newline="", encoding="utf-8") as handle:
    writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
    writer.writeheader()
    writer.writerows(rows)

json_path.write_text(json.dumps(rows, indent=2), encoding="utf-8")

main_rows = [row for row in rows if str(row["scenario"]).startswith("main-") and int(row["return_code"]) == 0]
summary: dict[str, dict] = {}
for row in main_rows:
    key = f"{row['resolution_id']}|{row['profile']}"
    summary[key] = {
        "resolution_id": row["resolution_id"],
        "profile": row["profile"],
        "wall_x_realtime": row["wall_x_realtime"],
        "elapsed_s": row["elapsed_s"],
        "clip_duration_s": row["clip_duration_s"],
        "output": f"{row['output_width']}x{row['output_height']}",
    }

payload = {
    "duration_seconds": DURATION_SECONDS,
    "total_cases": len(rows),
    "failed_cases": [row["scenario"] for row in rows if int(row["return_code"]) != 0],
    "main_matrix": summary,
    "artifacts": {
        "results_csv": str(csv_path),
        "results_json": str(json_path),
    },
}
summary_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")

print("[bench] summary:")
print(json.dumps(payload, indent=2))
PY

          tar -C "${BENCH_BASE}" -czf "${BENCH_BASE}.tar.gz" .
          echo "BENCH_ARTIFACT=${BENCH_BASE}.tar.gz"
          EOF

      - name: Download benchmark artifact from VPS
        env:
          VPS_HOST: ${{ secrets.VPS_HOST }}
          VPS_USER: ${{ secrets.VPS_USER }}
          VPS_PORT: ${{ secrets.VPS_PORT }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          PORT="${VPS_PORT:-22}"
          REMOTE_TAR="/tmp/poverlay-staging-bench-${RUN_ID}.tar.gz"
          mkdir -p benchmark-artifacts
          scp -P "${PORT}" "${VPS_USER}@${VPS_HOST}:${REMOTE_TAR}" "benchmark-artifacts/staging-render-benchmark-${RUN_ID}.tar.gz"
          tar -C benchmark-artifacts -xzf "benchmark-artifacts/staging-render-benchmark-${RUN_ID}.tar.gz"
          ls -la benchmark-artifacts
          cat benchmark-artifacts/summary.json

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: staging-render-benchmark-${{ github.run_id }}
          path: benchmark-artifacts/
